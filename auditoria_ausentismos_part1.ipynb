{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17e9205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIAGN√ìSTICO DEL ARCHIVO ===\n",
      "L√≠nea 0: Ôªø\"Exportado a CSV el martes, 26 de agosto de 2025\"...\n",
      "L√≠nea 1: ...\n",
      "L√≠nea 2: \"ID personal\",\"Nombre completo\",\"Cod Funci√≥n (externalCode)\",\"Cod Funci√≥n (Label)\",\"Tipo de Document...\n",
      "L√≠nea 3: \"80008153\",\"Alex David Alvarez Vergara\",\"80000253\",\"Operador de Tienda\",\"CitizenshipCardID\",\"1005568...\n",
      "L√≠nea 4: \"80008153\",\"Alex David Alvarez Vergara\",\"80000253\",\"Operador de Tienda\",\"CitizenshipCardID\",\"1005568...\n",
      "\n",
      "Probando diferentes configuraciones:\n",
      "Sin skiprows: 1 columnas, primera columna: Exportado a CSV el martes, 26 de agosto de 2025\n",
      "Skiprows=1: 37 columnas, primera columna: ID personal\n",
      "Skiprows=2: 37 columnas, primera columna: ID personal\n",
      "\n",
      "==================================================\n",
      "=== PROCESAMIENTO DE AUSENTISMOS ===\n",
      "1. Leyendo archivo CSV...\n",
      "   ‚úì Archivo le√≠do: 196543 filas, 37 columnas\n",
      "   ‚úì Primeras columnas: ['ID personal', 'Nombre completo', 'Cod Funci√≥n (externalCode)', 'Cod Funci√≥n (Label)', 'Tipo de Documento de Identidad']\n",
      "\n",
      "2. Verificando columnas requeridas...\n",
      "   ‚úì Columnas encontradas: 22/22\n",
      "\n",
      "3. Extrayendo columnas espec√≠ficas...\n",
      "   ‚úì DataFrame espec√≠fico: (196543, 22)\n",
      "\n",
      "4. Verificando primeros datos...\n",
      "   ID personal: 80008153\n",
      "   Nombre: Alex David Alvarez Vergara\n",
      "   Fecha inicio: 27/02/2023\n",
      "\n",
      "5. Aplicando mapeo de columnas y agregando homologaci√≥n...\n",
      "   üîß Creando columna de homologaci√≥n SSF vs SAP...\n",
      "   ‚úì Homologaci√≥n aplicada: 196543/196543 c√≥digos encontrados\n",
      "   üìã Ejemplos de homologaci√≥n:\n",
      "      CO_SICK ‚Üí 200\n",
      "      CO_FAMILY ‚Üí 205\n",
      "      CO_UNJ ‚Üí 380\n",
      "      CO_SICK ‚Üí 200\n",
      "      CO_SICK ‚Üí 200\n",
      "\n",
      "5.5 Creando columna NOMBRE_VALIDADOR...\n",
      "   üîß Mapeando c√≥digos de aprobador a nombres...\n",
      "   ‚úì Nombres de validadores mapeados: 196167/196543\n",
      "   ‚ö† ALERTA: 376 registros con validador no encontrado\n",
      "   ‚ö† C√≥digos de validadores no encontrados: ['60005045', '80008408', '62260380', '80011003', '80004364', '80003041', '80017304', '80006755', '80005469', '80026620']\n",
      "   üìã Ejemplos de mapeo de validadores:\n",
      "      60005057 ‚Üí Maria Lorena Ospina\n",
      "      62208433 ‚Üí Nini Johanna Neira\n",
      "      80025781 ‚Üí Yaima Motta Alejandra Lorena\n",
      "      80025780 ‚Üí Buitrago Baron Deisy Marley\n",
      "      80025781 ‚Üí Yaima Motta Alejandra Lorena\n",
      "\n",
      "5.55 Creando columnas SUB_TIPO y FSE...\n",
      "   üîß Mapeando c√≥digos de homologaci√≥n a Sub_tipo y FSE...\n",
      "   ‚úì Sub_tipo mapeados: 75854/196543\n",
      "   ‚úì FSE - Si Aplica: 17049\n",
      "   ‚úì FSE - No Aplica: 179494\n",
      "   ‚ö† ALERTA: C√≥digos sin Sub_tipo: ['205', '380', '100', '330', '340', '381', '345', '397', '198', '190', '191', '189', '197', '398', '196', '341', '331', '204']\n",
      "   üìã Ejemplos de mapeo Sub_tipo y FSE:\n",
      "      C√≥digo 200 ‚Üí Sub_tipo: 'Inca. Enfermedad  General', FSE: 'No Aplica'\n",
      "      C√≥digo 205 ‚Üí Sub_tipo: 'ALERTA SUB_TIPO NO ENCONTRADO', FSE: 'No Aplica'\n",
      "      C√≥digo 380 ‚Üí Sub_tipo: 'ALERTA SUB_TIPO NO ENCONTRADO', FSE: 'No Aplica'\n",
      "      C√≥digo 200 ‚Üí Sub_tipo: 'Inca. Enfermedad  General', FSE: 'No Aplica'\n",
      "      C√≥digo 200 ‚Üí Sub_tipo: 'Inca. Enfermedad  General', FSE: 'No Aplica'\n",
      "\n",
      "5.6 Creando columna LLAVE (SIN barras en fechas)...\n",
      "   üîß Limpiando fechas y creando llave SOLO CON N√öMEROS...\n",
      "   üìã Ejemplos de fechas ANTES de limpiar:\n",
      "      Fila 1: start='27/02/2023', end='28/02/2023'\n",
      "      Fila 2: start='23/05/2023', end='23/05/2023'\n",
      "      Fila 3: start='07/05/2023', end='07/05/2023'\n",
      "   üìã Ejemplos de fechas DESPU√âS de limpiar:\n",
      "      Fila 1: start='27022023', end='28022023'\n",
      "      Fila 2: start='23052023', end='23052023'\n",
      "      Fila 3: start='07052023', end='07052023'\n",
      "   ‚úì Columna llave creada con 196543 registros\n",
      "   üìã Ejemplos de llaves generadas (FINAL):\n",
      "      80008153 + 27022023 + 28022023 + 200 = 800081532702202328022023200\n",
      "      80008153 + 23052023 + 23052023 + 205 = 800081532305202323052023205\n",
      "      80008153 + 07052023 + 07052023 + 380 = 800081530705202307052023380\n",
      "      80008153 + 07042023 + 11042023 + 200 = 800081530704202311042023200\n",
      "      80008153 + 15102022 + 16102022 + 200 = 800081531510202216102022200\n",
      "   ‚ö† Se encontraron 165 llaves duplicadas\n",
      "   ‚úì Columnas renombradas: 27\n",
      "   ‚úì Columnas finales: 27 (incluyendo homologaci√≥n, llave, nombre_validador, sub_tipo y fse)\n",
      "\n",
      "6. Limpiando datos y guardando archivo...\n",
      "   üîß Corrigiendo numero_documento_identidad...\n",
      "   ‚úì Ejemplos corregidos: ['\"1005568317\"', '\"1005568317\"', '\"1005568317\"']\n",
      "   üîß Agregando prefijo a la llave para evitar notaci√≥n cient√≠fica...\n",
      "   ‚úì Ejemplos de llaves con prefijo: ['K800081532702202328022023200', 'K800081532305202323052023205', 'K800081530705202307052023380']\n",
      "   ‚úì Archivo guardado: C:\\Users\\jjbustos\\OneDrive - Grupo Jer√≥nimo Martins\\Documents\\auditoria ausentismos\\archivos_salida\\ausentismo_procesado_especifico.csv\n",
      "   ‚úì Registros procesados: 196543\n",
      "   ‚úì Columna nombre_validador agregada exitosamente\n",
      "   ‚úì Columnas sub_tipo y fse agregadas exitosamente\n",
      "\n",
      "=== RESUMEN FINAL ===\n",
      "Columnas procesadas: 27\n",
      " 1. id_personal\n",
      " 2. nombre_completo\n",
      " 3. cod_funcion_external_code\n",
      " 4. cod_funcion_label\n",
      " 5. tipo_documento_identidad\n",
      " 6. numero_documento_identidad\n",
      " 7. estado_empleado_picklist_label\n",
      " 8. external_code\n",
      " 9. external_name_label\n",
      "10. start_date\n",
      "11. end_date\n",
      "12. quantity_in_days\n",
      "13. calendar_days\n",
      "14. descripcion_general_external_code\n",
      "15. descripcion_general_picklist_label\n",
      "16. fecha_inicio_ausentismo\n",
      "17. agregador_global_ausencias_picklist_label\n",
      "18. last_modified_by\n",
      "19. last_approval_status_date\n",
      "20. hr_personnel_subarea\n",
      "21. hr_personnel_subarea_name\n",
      "22. approval_status\n",
      "23. homologacion_clase_de_ausentismo_ssf_vs_sap\n",
      "24. nombre_validador\n",
      "25. sub_tipo\n",
      "26. fse\n",
      "27. llave\n",
      "\n",
      "Primera fila de ejemplo:\n",
      "  id_personal: 80008153\n",
      "  nombre_completo: Alex David Alvarez Vergara\n",
      "  cod_funcion_external_code: 80000253\n",
      "  cod_funcion_label: Operador de Tienda\n",
      "  tipo_documento_identidad: CitizenshipCardID\n",
      "  numero_documento_identidad: \"1005568317\"\n",
      "  estado_empleado_picklist_label: Terminated\n",
      "  external_code: CO_SICK\n",
      "  external_name_label: Incapacidad enfermedad general\n",
      "  start_date: 27/02/2023\n",
      "  end_date: 28/02/2023\n",
      "  quantity_in_days: 2\n",
      "\n",
      "üìä ESTAD√çSTICAS DE HOMOLOGACI√ìN:\n",
      "   Total de c√≥digos √∫nicos homologados: 37\n",
      "   C√≥digos m√°s frecuentes:\n",
      "     205: 60765 registros\n",
      "     200: 48433 registros\n",
      "     100: 39069 registros\n",
      "     230: 13978 registros\n",
      "     380: 12855 registros\n",
      "\n",
      "üìã ESTAD√çSTICAS DE SUB_TIPO Y FSE:\n",
      "   Total de registros con Sub_tipo: 75854\n",
      "   üö® Registros con ALERTA SUB_TIPO NO ENCONTRADO: 120689\n",
      "   Distribuci√≥n FSE:\n",
      "     No Aplica: 179494 registros (91.3%)\n",
      "     Si Aplica: 17049 registros (8.7%)\n",
      "   Sub_tipos m√°s frecuentes:\n",
      "     Inca. Enfermedad  General: 48433 registros\n",
      "     Prorroga Inca/Enfer Gene: 13978 registros\n",
      "     Inc. Accidente de Trabajo: 2451 registros\n",
      "     Enf Gral SOAT: 2249 registros\n",
      "     Prorroga Enf Gral SOAT: 1812 registros\n",
      "\n",
      "üë§ ESTAD√çSTICAS DE VALIDADORES:\n",
      "   Total de validadores √∫nicos: 56\n",
      "   Validadores m√°s frecuentes:\n",
      "     Lenin Karina Triana: 20452 registros\n",
      "     Paula Estefania Cardenas Diaz: 18979 registros\n",
      "     Yeimy Velasco: 18437 registros\n",
      "     Johan Esteven Bernal Diaz: 12612 registros\n",
      "     Maria Alejandra Preciado: 10777 registros\n",
      "\n",
      "   üö® ALERTAS:\n",
      "     Registros con 'ALERTA VALIDADOR NO ENCONTRADO': 376\n",
      "     Porcentaje de alertas: 0.19%\n",
      "\n",
      "üîë ESTAD√çSTICAS DE LLAVES:\n",
      "   Total de llaves √∫nicas: 196378\n",
      "   Total de registros: 196543\n",
      "   ‚ö† Hay 165 llaves duplicadas\n",
      "\n",
      "‚úÖ PROCESO COMPLETADO EXITOSAMENTE\n",
      "   üìÅ Archivo guardado con 27 columnas\n",
      "   üìä 196543 registros procesados\n",
      "   üîë Columna llave creada exitosamente (SIN barras, CON prefijo K)\n",
      "   üë§ Columna nombre_validador agregada exitosamente\n",
      "   üìã Columnas sub_tipo y fse agregadas exitosamente\n",
      "\n",
      "==================================================\n",
      "=== AN√ÅLISIS DETALLADO DE NOMBRE_VALIDADOR ===\n",
      "\n",
      "Total de registros: 196543\n",
      "Registros con validador identificado: 196167\n",
      "Registros con ALERTA: 376\n",
      "Porcentaje con validador: 99.81%\n",
      "\n",
      "üö® ATENCI√ìN: 376 registros tienen 'ALERTA VALIDADOR NO ENCONTRADO'\n",
      "   Estos registros requieren revisi√≥n manual.\n",
      "\n",
      "üìã Top 10 validadores por frecuencia:\n",
      "    1. Lenin Karina Triana: 20452 registros (10.4%)\n",
      "    2. Paula Estefania Cardenas Diaz: 18979 registros (9.7%)\n",
      "    3. Yeimy Velasco: 18437 registros (9.4%)\n",
      "    4. Johan Esteven Bernal Diaz: 12612 registros (6.4%)\n",
      "    5. Maria Alejandra Preciado: 10777 registros (5.5%)\n",
      "    6. Juan Sebastian Sanabria Cabezas: 8722 registros (4.4%)\n",
      "    7. Hasbleidy Vanessa Rodriguez Beltran: 8512 registros (4.3%)\n",
      "    8. Maria Jose Alfonso: 8469 registros (4.3%)\n",
      "    9. Yaima Motta Alejandra Lorena: 7881 registros (4.0%)\n",
      "   10. Yuri Viviana Torres Garcia: 6748 registros (3.4%)\n",
      "\n",
      "‚úÖ Proceso completado. Revisa el archivo de salida para ver todos los datos.\n"
     ]
    }
   ],
   "source": [
    "# Auditor√≠a Ausentismos - Con Columna Nombre Validador\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Rutas de archivos\n",
    "ruta_entrada = r\"C:\\Users\\jjbustos\\OneDrive - Grupo Jer√≥nimo Martins\\Documents\\auditoria ausentismos\\archivos_planos\\AusentismoCOL-ApprovedPayrollIndicarfecha-Componente1.csv\"\n",
    "directorio_salida = r\"C:\\Users\\jjbustos\\OneDrive - Grupo Jer√≥nimo Martins\\Documents\\auditoria ausentismos\\archivos_salida\"\n",
    "archivo_salida = \"ausentismo_procesado_especifico.csv\"\n",
    "ruta_completa_salida = os.path.join(directorio_salida, archivo_salida)\n",
    "\n",
    "# Columnas que necesitas (22 columnas espec√≠ficas)\n",
    "columnas_requeridas = [\n",
    "    'ID personal',\n",
    "    'Nombre completo',\n",
    "    'Cod Funci√≥n (externalCode)',\n",
    "    'Cod Funci√≥n (Label)',\n",
    "    'Tipo de Documento de Identidad',\n",
    "    'N√∫mero de Documento de Identidad',\n",
    "    'Estado de empleado (Picklist Label)',\n",
    "    'externalCode',\n",
    "    'externalName (Label)',\n",
    "    'startDate',\n",
    "    'endDate',\n",
    "    'quantityInDays',\n",
    "    'Calendar Days',\n",
    "    'Descripci√≥n General (External Code)',\n",
    "    'Descripci√≥n General (Picklist Label)',\n",
    "    'Fecha de inicio de ausentismo',\n",
    "    'Agregador global de ausencias (Picklist Label)',\n",
    "    'lastModifiedBy',\n",
    "    'Last Approval Status Date',\n",
    "    'HR Personnel Subarea',\n",
    "    'HR Personnel Subarea Name',\n",
    "    'approvalStatus'\n",
    "]\n",
    "\n",
    "# Mapeo a snake_case (ahora incluye nombre_validador, sub_tipo y fse)\n",
    "mapeo_columnas = {\n",
    "    'ID personal': 'id_personal',\n",
    "    'Nombre completo': 'nombre_completo',\n",
    "    'Cod Funci√≥n (externalCode)': 'cod_funcion_external_code',\n",
    "    'Cod Funci√≥n (Label)': 'cod_funcion_label',\n",
    "    'Tipo de Documento de Identidad': 'tipo_documento_identidad',\n",
    "    'N√∫mero de Documento de Identidad': 'numero_documento_identidad',\n",
    "    'Estado de empleado (Picklist Label)': 'estado_empleado_picklist_label',\n",
    "    'externalCode': 'external_code',\n",
    "    'externalName (Label)': 'external_name_label',\n",
    "    'startDate': 'start_date',\n",
    "    'endDate': 'end_date',\n",
    "    'quantityInDays': 'quantity_in_days',\n",
    "    'Calendar Days': 'calendar_days',\n",
    "    'Descripci√≥n General (External Code)': 'descripcion_general_external_code',\n",
    "    'Descripci√≥n General (Picklist Label)': 'descripcion_general_picklist_label',\n",
    "    'Fecha de inicio de ausentismo': 'fecha_inicio_ausentismo',\n",
    "    'Agregador global de ausencias (Picklist Label)': 'agregador_global_ausencias_picklist_label',\n",
    "    'lastModifiedBy': 'last_modified_by',\n",
    "    'Last Approval Status Date': 'last_approval_status_date',\n",
    "    'HR Personnel Subarea': 'hr_personnel_subarea',\n",
    "    'HR Personnel Subarea Name': 'hr_personnel_subarea_name',\n",
    "    'approvalStatus': 'approval_status',\n",
    "    'Homologacion_clase_de_ausentismo_SSF_vs_SAP': 'homologacion_clase_de_ausentismo_ssf_vs_sap',\n",
    "    'llave': 'llave',\n",
    "    'nombre_validador': 'nombre_validador',\n",
    "    'Sub_tipo': 'sub_tipo',\n",
    "    'FSE': 'fse'\n",
    "}\n",
    "\n",
    "# Tabla de homologaci√≥n SSF vs SAP - COMPLETA\n",
    "tabla_homologacion = {\n",
    "    'CO_vacatio': '100',\n",
    "    'CO_SICK180': '188',\n",
    "    'CO_EXPSUSP': '189',\n",
    "    'CO_PAID': '190',\n",
    "    'CO_UNPAID': '191',\n",
    "    'CO_CTR_SEN': '198',\n",
    "    'CO_SICK': '200',\n",
    "    'CO_SICKINT': '201',\n",
    "    'CO_SICKSOA': '202',\n",
    "    'CO_PR_QRT': '204',\n",
    "    'CO_FAMILY': '205',\n",
    "    'CO_WORKACC': '215',\n",
    "    'CO_ILL': '230',\n",
    "    'CO_ILL_EXT': '231',\n",
    "    'CO_ILLSEXT': '232',\n",
    "    'CO_SICK540': '235',\n",
    "    'CO_WRKACXT': '250',\n",
    "    'CO_SICKSEN': '280',\n",
    "    'CO_MAT': '300',\n",
    "    'CO_MAT_SPE': '302',\n",
    "    'CO_MAT_ITR': '305',\n",
    "    'CO_PAT': '310',\n",
    "    'CO_PAT_INT': '311',\n",
    "    'CO_DOM_CAL': '330',\n",
    "    'CO_MOURN': '340',\n",
    "    'CO_UNJ': '380',\n",
    "    'CO_SUS': '381',\n",
    "    'CO_SHFT_SK': '383',\n",
    "    'CO_REG_WOS': '397',\n",
    "    'CO_MAT_INT': '301',\n",
    "    'CO_SICKARL': '187',\n",
    "    'CO_UNJ_INT': '197',\n",
    "    'CO_SCIT_SO': '203',\n",
    "    'CO_MOURN_I': '341',\n",
    "    'CO_WKACSEN': '281',\n",
    "    'CO_MAT_SEN': '398',\n",
    "    'CO_WRKACIT': '216',\n",
    "    'CO_INT_SUS': '195',\n",
    "    'CO_NONWORK': '192',\n",
    "    'CO_DELICAT': '206',\n",
    "    'CO_PR_QRTI': '334',\n",
    "    'CO_ILLSEIN': '233',\n",
    "    'CO_DM_CALI': '331',\n",
    "    'CO_VOTING': '345',\n",
    "    'CO_INT_UNP': '196',\n",
    "    'CO_FAM_FDS': '205',\n",
    "    'CO_VacationsFDS': '100'\n",
    "}\n",
    "\n",
    "# NUEVA TABLA: Mapeo de c√≥digos de aprobador a nombres\n",
    "tabla_validadores = {\n",
    "    '80002749': 'Diana Paola Martinez Diaz',\n",
    "    '62208433': 'Nini Johanna Neira',\n",
    "    '62208420': 'Maria Lorena Ospina',\n",
    "    '62208383': 'Juan Sebastian Sanabria Cabezas',\n",
    "    '62208367': 'Yeimy Velasco',\n",
    "    '60005132': 'Angie Paola Mu√±oz',\n",
    "    '80025780': 'Buitrago Baron Deisy Marley',\n",
    "    '80005980': 'Caro Salamanca Wilson Alfredo',\n",
    "    '80003719': 'Carre√±o Diaz Natalia Andrea',\n",
    "    '60005117': 'Daniela Maria Herrera',\n",
    "    '80022209': 'Guerra Cabrera Carolina',\n",
    "    '80025779': 'Huerfano Davila Edgar Andres',\n",
    "    '60005052': 'Jose Esteban Vargas',\n",
    "    '60006940': 'Juan Esteban Sanabria',\n",
    "    '60005371': 'Lenin Karina Triana',\n",
    "    '60005046': 'Luis Armando Chacon',\n",
    "    '60005129': 'Luz Liliana Rodriguez',\n",
    "    '60006593': 'Luz Liliana Rodriguez',\n",
    "    '60006112': 'Mancera Reinosa Diana Maria',\n",
    "    '60006909': 'Maria Jose Alfonso',\n",
    "    '60005057': 'Maria Lorena Ospina',\n",
    "    '80000523': 'Rodriguez Gutierrez Paula Marcela',\n",
    "    '80025781': 'Yaima Motta Alejandra Lorena',\n",
    "    '60006707': 'Yeimy Velasco',\n",
    "    '62212713': 'Andres Casta√±o',\n",
    "    '62212735': 'Diana Shirley Quiroga Cubillos',\n",
    "    '62214358': 'Paula Estefania Cardenas Diaz',\n",
    "    '62214530': 'Ana Milena Moyano Beltran',\n",
    "    '62212720': 'Lenin Karina Triana',\n",
    "    '62215253': 'Angie Marcela Carranza Arbelaez',\n",
    "    '62219343': 'Johan Esteven Bernal Diaz',\n",
    "    '62219327': 'Karen Ximena Casta√±eda Cristancho',\n",
    "    '62220971': 'Paula Estefania Cardenas Diaz',\n",
    "    '62222408': 'Julieth Lorena Pacheco Vargas',\n",
    "    '62214888': 'Liliana Espitia',\n",
    "    '62222738': 'Diana Shirley Quiroga Cubillos',\n",
    "    '62231004': 'Dayana Ramirez',\n",
    "    '62230354': 'Karen Ximena Casta√±eda Cristancho',\n",
    "    '62237396': 'Johan Esteven Bernal Diaz',\n",
    "    '62237293': 'Douglas Enrique Mora',\n",
    "    '62243896': 'Maria Alejandra Preciado',\n",
    "    '62246490': 'Norberto Alvarez',\n",
    "    '62252653': 'Hasbleidy Vanessa Rodriguez Beltran',\n",
    "    '62256597': 'Wilson Arley Perez',\n",
    "    '62259813': 'Ramiro Augusto Chavez',\n",
    "    '80024790': 'Heidy Maiyeth Alvarez',\n",
    "    '62256596': 'Alexander Parga',\n",
    "    '62261836': 'Sandra Milena Pinzon',\n",
    "    '62261839': 'Andrea Gissette Turizo',\n",
    "    '62266296': 'Nicol Estefani Porras',\n",
    "    '62273220': 'Erika Daniela Amaya Varela',\n",
    "    '62274136': 'Yuri Viviana Torres Garcia',\n",
    "    '62274134': 'Yeraldin Iveth Correa Mateus',\n",
    "    '62278611': 'Cesar Augusto Pinzon Calderon',\n",
    "    '62277236': 'Cristian Alexander Rodriguez Contreras',\n",
    "    '62274138': 'Angie Lureidy Avila Rodriguez',\n",
    "    '62287385': 'Luisa Fernanda Ardila Parra',\n",
    "    '62293397': 'Jenny Andrea Ramirez',\n",
    "    '62295420': 'Ana Maria Moreno Chavez',\n",
    "    '62295400': 'Nelson Javier Borrego Hernandez',\n",
    "    '62295415': 'Diana Marcela Castro Cardenas',\n",
    "    '62295417': 'Ruben Dario Villamizar Rojas',\n",
    "    '62295374': 'Diana Caterin Rojas Rivera'\n",
    "}\n",
    "\n",
    "# NUEVA TABLA: Mapeo de c√≥digo homologaci√≥n a Sub_tipo y FSE\n",
    "tabla_sub_tipo_fse = {\n",
    "    '200': {'sub_tipo': 'Inca. Enfermedad  General', 'fse': 'No Aplica'},\n",
    "    '230': {'sub_tipo': 'Prorroga Inca/Enfer Gene', 'fse': 'Si Aplica'},\n",
    "    '383': {'sub_tipo': 'Incapa.fuera de turno', 'fse': 'No Aplica'},\n",
    "    '215': {'sub_tipo': 'Inc. Accidente de Trabajo', 'fse': 'No Aplica'},\n",
    "    '202': {'sub_tipo': 'Enf Gral SOAT', 'fse': 'No Aplica'},\n",
    "    '232': {'sub_tipo': 'Prorroga Enf Gral SOAT', 'fse': 'Si Aplica'},\n",
    "    '310': {'sub_tipo': 'Licencia Paternidad', 'fse': 'No Aplica'},\n",
    "    '250': {'sub_tipo': 'Prorroga Inc. Accid. Trab', 'fse': 'Si Aplica'},\n",
    "    '280': {'sub_tipo': 'Incapacidad gral SENA', 'fse': 'No Aplica'},\n",
    "    '201': {'sub_tipo': 'Inca. Enfer Gral Integral', 'fse': 'No Aplica'},\n",
    "    '311': {'sub_tipo': 'Licencia Paternidad Inegr', 'fse': 'No Aplica'},\n",
    "    '300': {'sub_tipo': 'Licencia Maternidad', 'fse': 'No Aplica'},\n",
    "    '188': {'sub_tipo': 'Incap  mayor 180 dias', 'fse': 'No Aplica'},\n",
    "    '235': {'sub_tipo': 'Incap  mayor 540 dias', 'fse': 'No Aplica'},\n",
    "    '305': {'sub_tipo': 'Lic Mater Interrumpida', 'fse': 'No Aplica'},\n",
    "    '302': {'sub_tipo': 'Licencia Mater especial', 'fse': 'No Aplica'},\n",
    "    '203': {'sub_tipo': 'Enf Gral Int SOAT', 'fse': 'No Aplica'},\n",
    "    '210': {'sub_tipo': 'Inc. Enfer. General Hospi', 'fse': 'No Aplica'},\n",
    "    '231': {'sub_tipo': 'Prorr Inc/Enf Gral ntegra', 'fse': 'Si Aplica'},\n",
    "    '281': {'sub_tipo': 'Incapacidad ARL SENA', 'fse': 'No Aplica'},\n",
    "    '301': {'sub_tipo': 'Licencia Maternidad Integ', 'fse': 'No Aplica'}\n",
    "}\n",
    "\n",
    "def limpiar_fecha_para_llave(fecha_str):\n",
    "    \"\"\"\n",
    "    Funci√≥n que REALMENTE limpia las fechas para la llave - quita TODO lo que no sea n√∫mero\n",
    "    \"\"\"\n",
    "    if pd.isna(fecha_str) or fecha_str == '' or str(fecha_str).lower() in ['nan', 'none', 'nat']:\n",
    "        return ''\n",
    "    \n",
    "    # Convertir a string y quitar TODO lo que no sea d√≠gito\n",
    "    fecha_limpia = ''.join(c for c in str(fecha_str) if c.isdigit())\n",
    "    return fecha_limpia\n",
    "\n",
    "def procesar_archivo_ausentismos():\n",
    "    \"\"\"\n",
    "    Funci√≥n principal que procesa el archivo de ausentismos\n",
    "    \"\"\"\n",
    "    print(\"=== PROCESAMIENTO DE AUSENTISMOS ===\")\n",
    "    \n",
    "    try:\n",
    "        # PASO 1: Leer el archivo usando los headers que ya tiene\n",
    "        print(\"1. Leyendo archivo CSV...\")\n",
    "        \n",
    "        df = pd.read_csv(ruta_entrada, skiprows=2, encoding='utf-8', dtype=str)\n",
    "        \n",
    "        print(f\"   ‚úì Archivo le√≠do: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "        print(f\"   ‚úì Primeras columnas: {list(df.columns[:5])}\")\n",
    "        \n",
    "        # PASO 2: Verificar que tenemos las columnas que necesitamos\n",
    "        print(\"\\n2. Verificando columnas requeridas...\")\n",
    "        \n",
    "        columnas_encontradas = []\n",
    "        columnas_faltantes = []\n",
    "        \n",
    "        for col in columnas_requeridas:\n",
    "            if col in df.columns:\n",
    "                columnas_encontradas.append(col)\n",
    "            else:\n",
    "                columnas_faltantes.append(col)\n",
    "        \n",
    "        print(f\"   ‚úì Columnas encontradas: {len(columnas_encontradas)}/22\")\n",
    "        if columnas_faltantes:\n",
    "            print(f\"   ‚ö† Columnas faltantes: {columnas_faltantes}\")\n",
    "        \n",
    "        # PASO 3: Extraer solo las columnas que necesitamos\n",
    "        print(\"\\n3. Extrayendo columnas espec√≠ficas...\")\n",
    "        df_especifico = df[columnas_encontradas].copy()\n",
    "        \n",
    "        print(f\"   ‚úì DataFrame espec√≠fico: {df_especifico.shape}\")\n",
    "        \n",
    "        # PASO 4: Verificar los datos\n",
    "        print(\"\\n4. Verificando primeros datos...\")\n",
    "        print(f\"   ID personal: {df_especifico['ID personal'].iloc[0]}\")\n",
    "        print(f\"   Nombre: {df_especifico['Nombre completo'].iloc[0]}\")\n",
    "        print(f\"   Fecha inicio: {df_especifico['startDate'].iloc[0]}\")\n",
    "        \n",
    "        # PASO 5: Aplicar mapeo de nombres y agregar columna de homologaci√≥n\n",
    "        print(\"\\n5. Aplicando mapeo de columnas y agregando homologaci√≥n...\")\n",
    "        \n",
    "        # Crear la columna de homologaci√≥n ANTES del mapeo de nombres\n",
    "        if 'externalCode' in df_especifico.columns:\n",
    "            print(\"   üîß Creando columna de homologaci√≥n SSF vs SAP...\")\n",
    "            \n",
    "            df_especifico['Homologacion_clase_de_ausentismo_SSF_vs_SAP'] = df_especifico['externalCode'].map(tabla_homologacion)\n",
    "            \n",
    "            valores_encontrados = df_especifico['Homologacion_clase_de_ausentismo_SSF_vs_SAP'].notna().sum()\n",
    "            valores_totales = len(df_especifico)\n",
    "            valores_no_encontrados = valores_totales - valores_encontrados\n",
    "            \n",
    "            print(f\"   ‚úì Homologaci√≥n aplicada: {valores_encontrados}/{valores_totales} c√≥digos encontrados\")\n",
    "            if valores_no_encontrados > 0:\n",
    "                codigos_faltantes = df_especifico[df_especifico['Homologacion_clase_de_ausentismo_SSF_vs_SAP'].isna()]['externalCode'].unique()\n",
    "                print(f\"   ‚ö† C√≥digos no encontrados en tabla de homologaci√≥n: {list(codigos_faltantes)}\")\n",
    "            \n",
    "            print(\"   üìã Ejemplos de homologaci√≥n:\")\n",
    "            for i in range(min(5, len(df_especifico))):\n",
    "                codigo = df_especifico['externalCode'].iloc[i]\n",
    "                homolog = df_especifico['Homologacion_clase_de_ausentismo_SSF_vs_SAP'].iloc[i]\n",
    "                print(f\"      {codigo} ‚Üí {homolog}\")\n",
    "        \n",
    "        # PASO 5.5: CREAR COLUMNA NOMBRE_VALIDADOR\n",
    "        print(\"\\n5.5 Creando columna NOMBRE_VALIDADOR...\")\n",
    "        \n",
    "        if 'lastModifiedBy' in df_especifico.columns:\n",
    "            print(\"   üîß Mapeando c√≥digos de aprobador a nombres...\")\n",
    "            \n",
    "            df_especifico['lastModifiedBy_limpio'] = df_especifico['lastModifiedBy'].astype(str).str.strip()\n",
    "            \n",
    "            # Aplicar el mapeo y poner \"ALERTA VALIDADOR NO ENCONTRADO\" cuando no hay match\n",
    "            df_especifico['nombre_validador'] = df_especifico['lastModifiedBy_limpio'].map(tabla_validadores).fillna('ALERTA VALIDADOR NO ENCONTRADO')\n",
    "            \n",
    "            validadores_encontrados = (df_especifico['nombre_validador'] != 'ALERTA VALIDADOR NO ENCONTRADO').sum()\n",
    "            validadores_totales = len(df_especifico)\n",
    "            validadores_no_encontrados = validadores_totales - validadores_encontrados\n",
    "            \n",
    "            print(f\"   ‚úì Nombres de validadores mapeados: {validadores_encontrados}/{validadores_totales}\")\n",
    "            \n",
    "            if validadores_no_encontrados > 0:\n",
    "                codigos_validadores_faltantes = df_especifico[df_especifico['nombre_validador'] == 'ALERTA VALIDADOR NO ENCONTRADO']['lastModifiedBy_limpio'].unique()\n",
    "                print(f\"   ‚ö† ALERTA: {validadores_no_encontrados} registros con validador no encontrado\")\n",
    "                print(f\"   ‚ö† C√≥digos de validadores no encontrados: {list(codigos_validadores_faltantes)[:10]}\")\n",
    "            \n",
    "            print(\"   üìã Ejemplos de mapeo de validadores:\")\n",
    "            for i in range(min(5, len(df_especifico))):\n",
    "                codigo_val = df_especifico['lastModifiedBy_limpio'].iloc[i]\n",
    "                nombre_val = df_especifico['nombre_validador'].iloc[i]\n",
    "                print(f\"      {codigo_val} ‚Üí {nombre_val}\")\n",
    "            \n",
    "            df_especifico = df_especifico.drop(['lastModifiedBy_limpio'], axis=1)\n",
    "        else:\n",
    "            print(\"   ‚ùå No se encontr√≥ la columna 'lastModifiedBy'\")\n",
    "        \n",
    "        # PASO 5.55: CREAR COLUMNAS SUB_TIPO Y FSE\n",
    "        print(\"\\n5.55 Creando columnas SUB_TIPO y FSE...\")\n",
    "        \n",
    "        if 'Homologacion_clase_de_ausentismo_SSF_vs_SAP' in df_especifico.columns:\n",
    "            print(\"   üîß Mapeando c√≥digos de homologaci√≥n a Sub_tipo y FSE...\")\n",
    "            \n",
    "            # Crear las columnas usando el mapeo\n",
    "            df_especifico['Sub_tipo'] = df_especifico['Homologacion_clase_de_ausentismo_SSF_vs_SAP'].map(\n",
    "                lambda x: tabla_sub_tipo_fse.get(str(x), {}).get('sub_tipo', 'ALERTA SUB_TIPO NO ENCONTRADO') if pd.notna(x) else 'ALERTA SUB_TIPO NO ENCONTRADO'\n",
    "            )\n",
    "            \n",
    "            df_especifico['FSE'] = df_especifico['Homologacion_clase_de_ausentismo_SSF_vs_SAP'].map(\n",
    "                lambda x: tabla_sub_tipo_fse.get(str(x), {}).get('fse', 'No Aplica') if pd.notna(x) else 'No Aplica'\n",
    "            )\n",
    "            \n",
    "            # Contar valores encontrados\n",
    "            sub_tipo_encontrados = (df_especifico['Sub_tipo'] != 'ALERTA SUB_TIPO NO ENCONTRADO').sum()\n",
    "            fse_aplicables = (df_especifico['FSE'] == 'Si Aplica').sum()\n",
    "            fse_no_aplicables = (df_especifico['FSE'] == 'No Aplica').sum()\n",
    "            totales = len(df_especifico)\n",
    "            \n",
    "            print(f\"   ‚úì Sub_tipo mapeados: {sub_tipo_encontrados}/{totales}\")\n",
    "            print(f\"   ‚úì FSE - Si Aplica: {fse_aplicables}\")\n",
    "            print(f\"   ‚úì FSE - No Aplica: {fse_no_aplicables}\")\n",
    "            \n",
    "            # Mostrar c√≥digos no encontrados\n",
    "            codigos_no_encontrados = df_especifico[df_especifico['Sub_tipo'] == 'ALERTA SUB_TIPO NO ENCONTRADO']['Homologacion_clase_de_ausentismo_SSF_vs_SAP'].unique()\n",
    "            codigos_no_encontrados = [c for c in codigos_no_encontrados if pd.notna(c) and c != '']\n",
    "            if codigos_no_encontrados:\n",
    "                print(f\"   ‚ö† ALERTA: C√≥digos sin Sub_tipo: {list(codigos_no_encontrados)}\")\n",
    "            \n",
    "            # Mostrar ejemplos\n",
    "            print(\"   üìã Ejemplos de mapeo Sub_tipo y FSE:\")\n",
    "            for i in range(min(5, len(df_especifico))):\n",
    "                codigo_homolog = df_especifico['Homologacion_clase_de_ausentismo_SSF_vs_SAP'].iloc[i]\n",
    "                sub_tipo_val = df_especifico['Sub_tipo'].iloc[i]\n",
    "                fse_val = df_especifico['FSE'].iloc[i]\n",
    "                print(f\"      C√≥digo {codigo_homolog} ‚Üí Sub_tipo: '{sub_tipo_val}', FSE: '{fse_val}'\")\n",
    "        else:\n",
    "            print(\"   ‚ùå No se encontr√≥ la columna 'Homologacion_clase_de_ausentismo_SSF_vs_SAP'\")\n",
    "        \n",
    "        # PASO 5.6: CREAR COLUMNA LLAVE\n",
    "        print(\"\\n5.6 Creando columna LLAVE (SIN barras en fechas)...\")\n",
    "        \n",
    "        columnas_llave_originales = ['ID personal', 'startDate', 'endDate', 'Homologacion_clase_de_ausentismo_SSF_vs_SAP']\n",
    "        columnas_disponibles = all(col in df_especifico.columns for col in columnas_llave_originales)\n",
    "        \n",
    "        if columnas_disponibles:\n",
    "            print(\"   üîß Limpiando fechas y creando llave SOLO CON N√öMEROS...\")\n",
    "            \n",
    "            print(\"   üìã Ejemplos de fechas ANTES de limpiar:\")\n",
    "            for i in range(min(3, len(df_especifico))):\n",
    "                start_orig = df_especifico['startDate'].iloc[i]\n",
    "                end_orig = df_especifico['endDate'].iloc[i]\n",
    "                print(f\"      Fila {i+1}: start='{start_orig}', end='{end_orig}'\")\n",
    "            \n",
    "            df_especifico['startDate_limpia'] = df_especifico['startDate'].apply(limpiar_fecha_para_llave)\n",
    "            df_especifico['endDate_limpia'] = df_especifico['endDate'].apply(limpiar_fecha_para_llave)\n",
    "            \n",
    "            print(\"   üìã Ejemplos de fechas DESPU√âS de limpiar:\")\n",
    "            for i in range(min(3, len(df_especifico))):\n",
    "                start_limpia = df_especifico['startDate_limpia'].iloc[i]\n",
    "                end_limpia = df_especifico['endDate_limpia'].iloc[i]\n",
    "                print(f\"      Fila {i+1}: start='{start_limpia}', end='{end_limpia}'\")\n",
    "            \n",
    "            df_especifico['llave'] = (\n",
    "                df_especifico['ID personal'].astype(str).fillna('') +\n",
    "                df_especifico['startDate_limpia'] +\n",
    "                df_especifico['endDate_limpia'] +\n",
    "                df_especifico['Homologacion_clase_de_ausentismo_SSF_vs_SAP'].astype(str).fillna('')\n",
    "            )\n",
    "            \n",
    "            print(f\"   ‚úì Columna llave creada con {len(df_especifico)} registros\")\n",
    "            \n",
    "            print(\"   üìã Ejemplos de llaves generadas (FINAL):\")\n",
    "            for i in range(min(5, len(df_especifico))):\n",
    "                id_pers = df_especifico['ID personal'].iloc[i]\n",
    "                start_limpia = df_especifico['startDate_limpia'].iloc[i]\n",
    "                end_limpia = df_especifico['endDate_limpia'].iloc[i]\n",
    "                homolog = df_especifico['Homologacion_clase_de_ausentismo_SSF_vs_SAP'].iloc[i]\n",
    "                llave = df_especifico['llave'].iloc[i]\n",
    "                print(f\"      {id_pers} + {start_limpia} + {end_limpia} + {homolog} = {llave}\")\n",
    "            \n",
    "            df_especifico = df_especifico.drop(['startDate_limpia', 'endDate_limpia'], axis=1)\n",
    "            \n",
    "            duplicados = df_especifico['llave'].duplicated().sum()\n",
    "            if duplicados > 0:\n",
    "                print(f\"   ‚ö† Se encontraron {duplicados} llaves duplicadas\")\n",
    "            else:\n",
    "                print(f\"   ‚úÖ Todas las llaves son √∫nicas\")\n",
    "                \n",
    "        else:\n",
    "            print(\"   ‚ùå No se pueden crear las llaves - faltan columnas requeridas\")\n",
    "            columnas_faltantes_llave = [col for col in columnas_llave_originales if col not in df_especifico.columns]\n",
    "            print(f\"   ‚ùå Columnas faltantes: {columnas_faltantes_llave}\")\n",
    "        \n",
    "        mapeo_actual = {col: mapeo_columnas[col] for col in df_especifico.columns if col in mapeo_columnas}\n",
    "        df_final = df_especifico.rename(columns=mapeo_actual)\n",
    "        \n",
    "        print(f\"   ‚úì Columnas renombradas: {len(mapeo_actual)}\")\n",
    "        print(f\"   ‚úì Columnas finales: {len(df_final.columns)} (incluyendo homologaci√≥n, llave, nombre_validador, sub_tipo y fse)\")\n",
    "        \n",
    "        # PASO 6: Limpiar y guardar\n",
    "        print(\"\\n6. Limpiando datos y guardando archivo...\")\n",
    "        \n",
    "        if not os.path.exists(directorio_salida):\n",
    "            os.makedirs(directorio_salida)\n",
    "        \n",
    "        if 'tipo_documento_identidad' in df_final.columns:\n",
    "            df_final['tipo_documento_identidad'] = df_final['tipo_documento_identidad'].fillna('')\n",
    "        \n",
    "        if 'numero_documento_identidad' in df_final.columns:\n",
    "            print(\"   üîß Corrigiendo numero_documento_identidad...\")\n",
    "            df_final['numero_documento_identidad'] = df_final['numero_documento_identidad'].astype(str).replace('nan', '')\n",
    "            df_final['numero_documento_identidad'] = '\"' + df_final['numero_documento_identidad'] + '\"'\n",
    "            print(f\"   ‚úì Ejemplos corregidos: {df_final['numero_documento_identidad'].head(3).tolist()}\")\n",
    "        \n",
    "        if 'llave' in df_final.columns:\n",
    "            print(\"   üîß Agregando prefijo a la llave para evitar notaci√≥n cient√≠fica...\")\n",
    "            df_final['llave'] = 'K' + df_final['llave'].astype(str)\n",
    "            print(f\"   ‚úì Ejemplos de llaves con prefijo: {df_final['llave'].head(3).tolist()}\")\n",
    "        \n",
    "        df_final.to_csv(ruta_completa_salida, index=False, encoding='utf-8', quoting=2)\n",
    "        \n",
    "        print(f\"   ‚úì Archivo guardado: {ruta_completa_salida}\")\n",
    "        print(f\"   ‚úì Registros procesados: {len(df_final)}\")\n",
    "        print(f\"   ‚úì Columna nombre_validador agregada exitosamente\")\n",
    "        print(f\"   ‚úì Columnas sub_tipo y fse agregadas exitosamente\")\n",
    "        \n",
    "        # PASO 7: Mostrar resumen final\n",
    "        print(\"\\n=== RESUMEN FINAL ===\")\n",
    "        print(f\"Columnas procesadas: {len(df_final.columns)}\")\n",
    "        for i, col in enumerate(df_final.columns, 1):\n",
    "            print(f\"{i:2d}. {col}\")\n",
    "        \n",
    "        print(f\"\\nPrimera fila de ejemplo:\")\n",
    "        primera_fila = df_final.iloc[0]\n",
    "        for col in list(df_final.columns)[:12]:\n",
    "            print(f\"  {col}: {primera_fila[col]}\")\n",
    "        \n",
    "        if 'homologacion_clase_de_ausentismo_ssf_vs_sap' in df_final.columns:\n",
    "            print(f\"\\nüìä ESTAD√çSTICAS DE HOMOLOGACI√ìN:\")\n",
    "            homolog_stats = df_final['homologacion_clase_de_ausentismo_ssf_vs_sap'].value_counts()\n",
    "            print(f\"   Total de c√≥digos √∫nicos homologados: {len(homolog_stats)}\")\n",
    "            print(f\"   C√≥digos m√°s frecuentes:\")\n",
    "            for codigo, freq in homolog_stats.head(5).items():\n",
    "                print(f\"     {codigo}: {freq} registros\")\n",
    "        \n",
    "        if 'sub_tipo' in df_final.columns and 'fse' in df_final.columns:\n",
    "            print(f\"\\nüìã ESTAD√çSTICAS DE SUB_TIPO Y FSE:\")\n",
    "            \n",
    "            # Contar Sub_tipos con alerta\n",
    "            sub_tipo_alertas = (df_final['sub_tipo'] == 'ALERTA SUB_TIPO NO ENCONTRADO').sum()\n",
    "            sub_tipo_ok = (df_final['sub_tipo'] != 'ALERTA SUB_TIPO NO ENCONTRADO').sum()\n",
    "            \n",
    "            print(f\"   Total de registros con Sub_tipo: {sub_tipo_ok}\")\n",
    "            if sub_tipo_alertas > 0:\n",
    "                print(f\"   üö® Registros con ALERTA SUB_TIPO NO ENCONTRADO: {sub_tipo_alertas}\")\n",
    "            \n",
    "            # Contar por tipo de FSE\n",
    "            fse_stats = df_final['fse'].value_counts()\n",
    "            print(f\"   Distribuci√≥n FSE:\")\n",
    "            for fse_val, freq in fse_stats.items():\n",
    "                porcentaje = (freq / len(df_final)) * 100\n",
    "                print(f\"     {fse_val}: {freq} registros ({porcentaje:.1f}%)\")\n",
    "            \n",
    "            # Mostrar algunos Sub_tipos m√°s comunes (excluyendo alertas)\n",
    "            print(f\"   Sub_tipos m√°s frecuentes:\")\n",
    "            sub_tipo_stats = df_final[df_final['sub_tipo'] != 'ALERTA SUB_TIPO NO ENCONTRADO']['sub_tipo'].value_counts().head(5)\n",
    "            for sub_tipo_val, freq in sub_tipo_stats.items():\n",
    "                print(f\"     {sub_tipo_val}: {freq} registros\")\n",
    "        \n",
    "        if 'nombre_validador' in df_final.columns:\n",
    "            print(f\"\\nüë§ ESTAD√çSTICAS DE VALIDADORES:\")\n",
    "            validadores_stats = df_final['nombre_validador'].value_counts()\n",
    "            print(f\"   Total de validadores √∫nicos: {len(validadores_stats)}\")\n",
    "            print(f\"   Validadores m√°s frecuentes:\")\n",
    "            \n",
    "            # Contar los que tienen alerta\n",
    "            alertas_count = (df_final['nombre_validador'] == 'ALERTA VALIDADOR NO ENCONTRADO').sum()\n",
    "            \n",
    "            # Mostrar top 5 (excluyendo las alertas para el top)\n",
    "            top_validadores = df_final[df_final['nombre_validador'] != 'ALERTA VALIDADOR NO ENCONTRADO']['nombre_validador'].value_counts().head(5)\n",
    "            for nombre, freq in top_validadores.items():\n",
    "                print(f\"     {nombre}: {freq} registros\")\n",
    "            \n",
    "            if alertas_count > 0:\n",
    "                print(f\"\\n   üö® ALERTAS:\")\n",
    "                print(f\"     Registros con 'ALERTA VALIDADOR NO ENCONTRADO': {alertas_count}\")\n",
    "                porcentaje_alerta = (alertas_count / len(df_final)) * 100\n",
    "                print(f\"     Porcentaje de alertas: {porcentaje_alerta:.2f}%\")\n",
    "        \n",
    "        if 'llave' in df_final.columns:\n",
    "            print(f\"\\nüîë ESTAD√çSTICAS DE LLAVES:\")\n",
    "            llaves_unicas = df_final['llave'].nunique()\n",
    "            total_registros = len(df_final)\n",
    "            print(f\"   Total de llaves √∫nicas: {llaves_unicas}\")\n",
    "            print(f\"   Total de registros: {total_registros}\")\n",
    "            if llaves_unicas == total_registros:\n",
    "                print(f\"   ‚úÖ Todas las llaves son √∫nicas\")\n",
    "            else:\n",
    "                print(f\"   ‚ö† Hay {total_registros - llaves_unicas} llaves duplicadas\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ PROCESO COMPLETADO EXITOSAMENTE\")\n",
    "        print(f\"   üìÅ Archivo guardado con {len(df_final.columns)} columnas\")\n",
    "        print(f\"   üìä {len(df_final)} registros procesados\")\n",
    "        print(f\"   üîë Columna llave creada exitosamente (SIN barras, CON prefijo K)\")\n",
    "        print(f\"   üë§ Columna nombre_validador agregada exitosamente\")\n",
    "        print(f\"   üìã Columnas sub_tipo y fse agregadas exitosamente\")\n",
    "        return df_final\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "def diagnostico_archivo():\n",
    "    \"\"\"\n",
    "    Funci√≥n de diagn√≥stico para entender la estructura del archivo\n",
    "    \"\"\"\n",
    "    print(\"=== DIAGN√ìSTICO DEL ARCHIVO ===\")\n",
    "    \n",
    "    with open(ruta_entrada, 'r', encoding='utf-8') as file:\n",
    "        for i in range(5):\n",
    "            linea = file.readline().strip()\n",
    "            print(f\"L√≠nea {i}: {linea[:100]}...\")\n",
    "    \n",
    "    print(\"\\nProbando diferentes configuraciones:\")\n",
    "    \n",
    "    configs = [\n",
    "        {\"skiprows\": 0, \"desc\": \"Sin skiprows\"},\n",
    "        {\"skiprows\": 1, \"desc\": \"Skiprows=1\"},\n",
    "        {\"skiprows\": 2, \"desc\": \"Skiprows=2\"},\n",
    "    ]\n",
    "    \n",
    "    for config in configs:\n",
    "        try:\n",
    "            df_test = pd.read_csv(ruta_entrada, nrows=2, encoding='utf-8', **{k:v for k,v in config.items() if k != 'desc'})\n",
    "            print(f\"{config['desc']}: {df_test.shape[1]} columnas, primera columna: {df_test.columns[0]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{config['desc']}: Error - {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    diagnostico_archivo()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    resultado = procesar_archivo_ausentismos()\n",
    "    \n",
    "    if resultado is not None and 'nombre_validador' in resultado.columns:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"=== AN√ÅLISIS DETALLADO DE NOMBRE_VALIDADOR ===\")\n",
    "        print(f\"\\nTotal de registros: {len(resultado)}\")\n",
    "        \n",
    "        registros_con_validador = (resultado['nombre_validador'] != 'ALERTA VALIDADOR NO ENCONTRADO').sum()\n",
    "        registros_sin_validador = (resultado['nombre_validador'] == 'ALERTA VALIDADOR NO ENCONTRADO').sum()\n",
    "        \n",
    "        print(f\"Registros con validador identificado: {registros_con_validador}\")\n",
    "        print(f\"Registros con ALERTA: {registros_sin_validador}\")\n",
    "        print(f\"Porcentaje con validador: {(registros_con_validador / len(resultado) * 100):.2f}%\")\n",
    "        \n",
    "        if registros_sin_validador > 0:\n",
    "            print(f\"\\nüö® ATENCI√ìN: {registros_sin_validador} registros tienen 'ALERTA VALIDADOR NO ENCONTRADO'\")\n",
    "            print(\"   Estos registros requieren revisi√≥n manual.\")\n",
    "        \n",
    "        print(\"\\nüìã Top 10 validadores por frecuencia:\")\n",
    "        top_validadores = resultado[resultado['nombre_validador'] != 'ALERTA VALIDADOR NO ENCONTRADO']['nombre_validador'].value_counts().head(10)\n",
    "        for i, (nombre, cantidad) in enumerate(top_validadores.items(), 1):\n",
    "            porcentaje = (cantidad / len(resultado)) * 100\n",
    "            print(f\"   {i:2d}. {nombre}: {cantidad} registros ({porcentaje:.1f}%)\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Proceso completado. Revisa el archivo de salida para ver todos los datos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jeysshon_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
